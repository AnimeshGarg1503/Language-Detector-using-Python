{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageTranslationAndDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q\n",
        "!pip install googletrans"
      ],
      "metadata": {
        "id": "_OVvA_Vu-MwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91aafdaf-2ff4-41af-b3a0-85e1ca4a5dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.1 MB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 111 kB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 63.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 24.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 232 kB 78.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 164 kB 44.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 53.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 793 kB 67.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 44.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 428 kB 59.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 381 kB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.6 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Collecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 20.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2022.6.15)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15735 sha256=f9d6e3ef63e84bc57298d4deea1998b991154bbd1abf65712fe261ec60aa5aa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/da/eb/a54579056f265eede0417df537dd56d3df5b9eb2b25df0003d\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY-GjE9kQ7wi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from googletrans import Translator\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import pickle\n",
        "import cv2 as cv2\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation_text = input('Enter your text here: ')\n",
        "\n",
        "required_transalation_language = input('Enter your required translation language: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edzz5VgDRaWw",
        "outputId": "9ec4e3b4-396b-4824-fef6-017aba502eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your text here: Hey\n",
            "Enter your required translation language: hindi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "# to store every sentence entered. \n",
        "translation = []\n",
        "for i in translation_text.split('.'):\n",
        "  translation.append(translator.translate(i, dest=required_transalation_language).text)\n",
        "\n",
        "#converting it to proper capitalization and storing back in a string to produce the output.\n",
        "translated_string = ''\n",
        "temp_string = ''\n",
        "for j in translation:\n",
        "    \n",
        "    temp_string = j.capitalize()\n",
        "    translated_string = translated_string + temp_string  + '.' + ' ' \n"
      ],
      "metadata": {
        "id": "rEt9No_GRhhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-jWp4-jtekWn",
        "outputId": "76dbae38-7d3c-4982-fb06-5c608c082a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'अरे. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "languages_data = pd.read_csv(\"/content/languages_dataset.csv\")\n",
        "print(languages_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwsUeWd1crtF",
        "outputId": "90f871ef-eae7-4608-f657-47940a967e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  language\n",
            "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
            "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
            "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
            "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
            "4  de spons behoort tot het geslacht haliclona en...     Dutch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(languages_data[\"Text\"])\n",
        "y = np.array(languages_data[\"language\"])\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=1503)"
      ],
      "metadata": {
        "id": "6GDriGpMf-4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train,y_train)\n",
        "model.score(X_test,y_test)\n",
        "\n",
        "plt.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V17fcw5-hScf",
        "outputId": "50ce84c0-2e4b-453d-db09-132592cc4d0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9847878787878788"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = cv.transform([translation_text]).toarray()\n",
        "\n",
        "output = model.predict(data)\n",
        "print('Detected language is', str(output),'.','\\nThe translation is: \\n\\n\\t ',translated_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7d9nWkZhUZz",
        "outputId": "01c84011-f94f-4078-9e46-cf638f751a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language is ['Chinese'] . \n",
            "The translation is: \n",
            "\n",
            "\t  अरे. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'trained_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "w-1kXtHG1WzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('trained_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "5Wv-egXZ1ldx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = cv.transform([translation_text]).toarray()\n",
        "output = model.predict(data)\n",
        "print('Detected language is', str(output),'.','\\nThe translation is: \\n\\n\\t ',translated_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jew_YBzk11az",
        "outputId": "c0efc574-aa9d-4df3-cc70-f39b126eddb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language is ['Chinese'] . \n",
            "The translation is: \n",
            "\n",
            "\t  अरे. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rnu7lfqj2GnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import pandas as pd\n",
        "from googletrans import Translator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import pickle\n",
        "\n",
        "# loading the saved model\n",
        "loaded_model = pickle.load(open('/content/trained_model.sav', 'rb'))\n",
        "\n",
        "\n",
        "def translate(in_lang,tr_lang):\n",
        "  translation_text = in_lang\n",
        "  required_transalation_language = tr_lang\n",
        "  translator = Translator()\n",
        "  # to store every sentence entered. \n",
        "  translation = []\n",
        "  for i in translation_text.split('.'):\n",
        "    translation.append(translator.translate(i, dest=required_transalation_language).text)\n",
        "\n",
        "  #converting it to proper capitalization and storing back in a string to produce the output.\n",
        "  translated_string = ''\n",
        "  temp_string = ''\n",
        "  for j in translation:\n",
        "    \n",
        "    temp_string = j.capitalize()\n",
        "    translated_string = translated_string + temp_string  + '.' + ' ' \n",
        "  data = cv.transform([translation_text]).toarray()\n",
        "\n",
        "  output = model.predict(data)\n",
        "  return print('Detected language is ', str(output),'.','\\nThe translation is: \\n\\n\\t ',translated_string)\n",
        "\n",
        "  \n",
        "  \n",
        "st.title('Welcome to this Language translator.\\nLet\\'s break the Language Barrier together!' )\n",
        " \n",
        "in_lang = st.text_input(\"Please enter your text here\")\n",
        "tr_lang = st.text_input(\"Please enter your required translated language here\")\n",
        "\n",
        "output = ''\n",
        "tr_button = st.button('Translate')\n",
        "\n",
        "if tr_button:\n",
        "  output = translate(in_lang, tr_lang)\n",
        "  st.text('Hope it helps!')\n",
        "st.success(output)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJV--_aE2Muw",
        "outputId": "ea1cae7a-021f-43ee-8b42-0bda52c27ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kniIKZ6Vqa4I",
        "outputId": "495530b6-f8be-4482-9329-26a430815c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: streamlit: command not found\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.695s\n",
            "your url is: https://some-lies-watch-34-73-214-128.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}